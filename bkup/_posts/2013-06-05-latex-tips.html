---
layout: post
title: LaTeX Tips
categories: []
tags: []
status: publish
type: post
published: true
meta:
  _publicize_pending: '1'
  _wpas_done_373263: '1'
  _publicize_done_external: a:1:{s:8:"linkedin";a:1:{s:10:"DFfbe-Shd5";b:1;}}
author: 
---
<p>\algsetup{linenosize=\tiny}	% font size of line number<br />
\scriptsize 	% font size of algorithm<br />
\caption{Approximate Learning Algorithm for a Fully Boltzmann Machine} 	% name of the algorithm<br />
\label{ala} 	% reference of this algorithm<br />
\begin{algorithmic}[1]<br />
\STATE Given a data set $X=\lbrace x^1,...,x^N \rbrace $ randomly initialize $\theta^0$ and $M$ sample particles $\lbrace {\tilde { x } }^{ 0,1 }, \cdots, {\tilde { x }}^{ 0,M } \rbrace$.<br />
\FOR{$t=0:T$(number of iterations)}<br />
	\FOR{$i=1:M$(number of parallel Markov chains)}<br />
		\STATE Sample ${\tilde { x } }^{ t+1,i }$ given 	${\tilde { x }  }^{ t,i }$ using transition operator $T_{\theta^t}({\tilde { x }  }^{ t+1,i } \gets {\tilde { x }  }^{ t+,i } )$.<br />
	\ENDFOR<br />
	\STATE Using statistics vector $\Phi$ update: \\ $\theta^{t+1}=\theta^t + \alpha_t \left[ \frac{1}{N} \sum_{n=1}^{N} \Phi(x^n) - \frac{1}{M} \sum_{m=1}^{M} \Phi({\tilde { x } }^{ t+1,m } ) \right]$.<br />
	\STATE Decrease $\alpha_t$.<br />
\ENDFOR<br />
\end{algorithmic}<br />
\end{algorithm}</p>
